\section{Introduction} \label{sec:introduction}

Contemporary advances in the engineering and manufacture of compute hardware largely come as a double-edged sword.
Fundamental physical limitations have essentially curtailed transformative progress in capabilities of individual processing elements \citep{sutter2005free}.
Instead, the frontier of raw compute power in high-performance computing (HPC) has largely been driven forward by scale-out to multi- and many-core architectures \citep{morgenstern2021unparalleled}.
On the flip side, economization and miniaturization has driven broad dissemination of computing capability through the Internet of Things (IoT) revolution \citep{rfc7228,ojo2018review}.
A notable pattern cuts across some facets of both fringes: absolute reduction or tightening or relative tightening in resources and capabilities per processing element, particularly with respect to the capacity, latency, or bandwidth of memory and storage.

Along the march to exascale HPC, processing capacity growth (e.g., FLOPS) has outpaced memory performance and capacity --- particularly with respect to hardware accelerators \citep{kogge2013exascale,khan2021analysis}.
This ``memory wall'' bottlenecks throughput unless memory access volume is kept sufficiently low in proportion to processing workload (i.e., high ``arithmetic'' or ``operational'' intensity is achieved) \citep{obviousmemorywall,mckee2004reflections,ROOFLINEMODEL2008Berkley}.
Analogous performance trajectories have played out with respect to data storage \citep{heldens2020landscape,kunkel2014exascale}, imposing an analogous ``storage wall'' bottleneck \citep{hu2016storage}.
Recent introduction of the Cerebras Wafer-Scale Engine epitomizes the double-edged nature of recent HPC trends: this accelerator packages an astounding 850,000 computing elements onto a single piece of silicon, but restricts endows each with a modest 48kb of memory and provisions an exclusively-local mesh communication model \citep{cerebras2021wafer,lauterbach2021path}.

Low-end hardware, on the other hand, marches toward the downscale and ubiquity of ``smart dust'' \citep{warneke2001smart}.
The ``Michigan Micro Mote'' constitutes a notable waypoint \citep{lee2012modular}.
These devices occupy only a cubic millimeter of volume, but provision a mere 3 kb of retentive memory.
Introduced in 2012, applications have since been explored across imaging, motion detection, pressure measurement, and electrocardiography monitoring \citep{lee2015review}.
Taking for instance another more recent high-profile project, computational capacity was recently tucked into wireless sensor network devices adopting the form factor of dandelion parachutes \citep{iyer2022wind}.
The chipset for these devices provisions 2 kilobytes of volatile flash memory --- and a mere 128 bytes of retentive memory \citep{microchip2014atiny20}.
% Even more striking is the advent of an epidermal physiological sensor equipped with carbon nanotube-based flash memory of a scant 48 bytes \citep{xiang2022epidermal}.
The ever abiding race to plumb the very lower limits of technical feasibility seems likely to keep bare-bones computing modalities front and center within this engineering domain far into the future.

The intersection of these observations is that despite relentless technological advancement, severely resource-limited computation will persist.
In fact, in some domains technological progress has actually elevated the relevance of resource-limited computation.
These trends, and the wider context of surging generation of digital data \citep{bhat2018data}, demand attention to algorithmic strategies to triage memory/storage-capacity gaps.


\begin{itemize}
  \item mention outline: creation of ubiquitous, irregular, decentralized sensor networks to scientific computing to digital evolution
  \item justify talking aobut digital evolution as it being of particular relevance to the algorithm at hand and maybe even mention as original motivation
  \item when zooming in to digital evolution, be sure to note we will zoom back out again
\end{itemize}

\begin{itemize}
  \item scaling-up is of particualar interest in digital evolution
  \item open-ended evolution --- compute-limited? \citep{channon2019maximum, taylor2016open}
  \item could more compute power create a paradigm shift in the field (cite my dissertation, other stuff???)
  \item approaches using existing traditional cluster hardware ( \citep{moreno2021conduit}; cite sentient)
  \item approaches using specialized accelerators (e.g., GPU)
  \item approaches using bespoke mesh hardware (Illuminato X Machina \citep{schulte2010genetic})
  \item despite fledgling , methods for application of parallel computing power to open-ended evolutionary simulation is largely unexplored (infancy, rudimentary, etc).
\end{itemize}

\begin{itemize}
  \item but it introduces experimental issues
  \item perfect reproducbility goes away
  \item throwing data away == losing data (look for times where perfect observability was crucial? richness/different number of phenotypes present? spatial analyses!!! <<-- this is the good one)
  \item should mention general observability issues (TODO brainstorm)
  \item ... but also phylogenetics (need cites about why phylogenetics is important)
  \item move from perfect tracking (centralized) to nature-inspred decentralized inference? (cite that this has been done in DISHTINY using bitstring tags \citep{moreno2021case})
  \item talk about natural phylogenetics as a distributed system
  \item tradeoffs: perfect tracking is very efficient for single core (mention proofs)
  \item hereditary stratigraphy (find cites): using checkpoint fingerprints
  \item turns out this is the same problem as ``data disposal problem''
\end{itemize}

\begin{itemize}
  \item this generalizes to broader question of replicating digital artifacts
  \item digital media and computer viruses
  \item existing studies generally employ centralized tracking
  \begin{itemize}
    \item image/text snippet sharing on facebook \citep{friggeri2014rumor}
    \item Experiments studying the propagation of computer viruses with centralized instrumentation \citep{cohen1987computer} (want more cites)
  \end{itemize}
  \item interesting instance of reconstruction that shares a lot in common with hereditary stratigraphy: chain email sharing \citep{libennowell2008tracing}
\end{itemize}

\begin{itemize}
  \item IoT/wireless sensor networks
  \item low power/capacity hardware: smart dust \citep{warneke2001smart}
  \item run out of space:
  \begin{itemize}
    \item long-duration solar-powered sensor --- battery is not limiting factor \citep{corke2007long}
    \item not just limited onboard memory
    \item high frequency data \citep{luharuka2003design}
  \end{itemize}
  \item common theme: irregular connectivity
  \begin{itemize}
    \item communicication outages/disruptions (need cite)
    \item query-based networks (need cite) (note ``security'' applications where desired content is only known long after the fact?)
    \item mobile sinks \citep{jain2022survey} (for security, power efficiency (fewer hops), reduce bottlenecking)
    \item at the very extreme are autonomous loggers
    \item logger: new data discarded once full \citep{saunders1989portable,mahzan2017design}
    \item logger: new data replaces oldest data (flight data recorder; need cite)
    \item logger: pplication-specific online compression algorithm that (\citep{hadiatna2016design} increases capacity twofold)
  \end{itemize}
  \item more data coming in from everywhere, also need a principled strategy to triage ``record management'' in centralized storage
  \item end on: need a principled way to weed time series data on the fly that meets coverage requirements at any point in time
  \item ``data disposal problem''
\end{itemize}

then outline paper

intro

preliminaries

perfect Tracking

policies

discussion
