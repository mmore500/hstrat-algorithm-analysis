\section{Introduction} \label{sec:introduction}

Contemporary advances in the engineering and manufacture of compute hardware largely come as a double-edged sword.
Fundamental physical limitations have essentially curtailed transformative progress in capabilities of individual processing elements \citep{sutter2005free}.
Instead, the frontier of raw compute power in high-performance computing (HPC) has largely been driven forward by scale-out to multi- and many-core architectures \citep{morgenstern2021unparalleled}.
On the flip side, economization and miniaturization has driven broad dissemination of computing capability through the Internet of Things (IoT) revolution \citep{rfc7228,ojo2018review}.
A notable pattern cuts across some facets of both fringes: absolute reduction or tightening or relative tightening in resources and capabilities per processing element, particularly with respect to the capacity, latency, or bandwidth of memory and storage.

Along the march to exascale HPC, processing capacity growth (e.g., FLOPS) has outpaced memory performance and capacity --- particularly with respect to hardware accelerators \citep{kogge2013exascale,khan2021analysis}.
This ``memory wall'' bottlenecks throughput unless memory access volume is kept sufficiently low in proportion to processing workload (i.e., high ``arithmetic'' or ``operational'' intensity is achieved) \citep{obviousmemorywall,mckee2004reflections,ROOFLINEMODEL2008Berkley}.
Analogous performance trajectories have played out with respect to data storage \citep{heldens2020landscape,kunkel2014exascale}, imposing an analogous ``storage wall'' bottleneck \citep{hu2016storage}.
Recent introduction of the Cerebras Wafer-Scale Engine epitomizes the double-edged nature of recent HPC trends: this accelerator packages an astounding 850,000 computing elements onto a single piece of silicon, but restricts endows each with a modest 48kb of memory and provisions an exclusively-local mesh communication model \citep{cerebras2021wafer,lauterbach2021path}.

Low-end hardware, on the other hand, marches toward the downscale and ubiquity of ``smart dust'' \citep{warneke2001smart}.
The ``Michigan Micro Mote'' constitutes a notable waypoint \citep{lee2012modular}.
These devices occupy only a cubic millimeter of volume, but provision a mere 3 kb of retentive memory.
Introduced in 2012, applications have since been explored across imaging, motion detection, pressure measurement, and electrocardiography monitoring \citep{lee2015review}.
Taking for instance another more recent high-profile project, computational capacity was recently tucked into wireless sensor network devices adopting the form factor of dandelion parachutes \citep{iyer2022wind}.
The chipset for these devices provisions 2 kilobytes of volatile flash memory --- and a mere 128 bytes of retentive memory \citep{microchip2014atiny20}.
% Even more striking is the advent of an epidermal physiological sensor equipped with carbon nanotube-based flash memory of a scant 48 bytes \citep{xiang2022epidermal}.
The ever abiding race to plumb the very lower limits of technical feasibility seems likely to keep bare-bones computing modalities front and center within this engineering domain far into the future.

The intersection of these observations is that despite relentless technological advancement, severely resource-limited computation will persist.
In fact, in some domains technological progress has actually elevated the relevance of resource-limited computation.
These trends, and the wider context of surging generation of digital data \citep{bhat2018data}, demand attention to algorithmic strategies to triage memory/storage-capacity gaps.

Burgeoning computational power has been broadly envisaged as driving force in advancing the field of digital evolution and, more broadly, artificial life \citep{ackley2014indefinitely}.
In fact, a central motif in the field --- the problem of open-ended evolution, how and if closed systems can yield indefinitely yield new complexity, novelty, and adaptation --- is inexorably intertwined with computational scale, and has been implicated as meaningfully compute-constrained in at least some systems \citep{taylor2016open,channon2019maximum}.
It is not an unreasonable possibility that orders-of-magnitude changes in computational power could induce qualitative changes in digital evolution and artificial life systems \citep{moreno2022engineering}, analogously to the renaissance of deep learning with the advent of GPGPU computing \citep{krizhevsky2012imagenet}.
To accomplish such, however, will require contending with scaling challenges induced by aforementioned hardware trends.

Parallel and distributed computing is, indeed, widely leveraged in digital evolution.
Applications range from processing entirely independent evolutionary replicates across compute jobs \citep{dolson2017spatial, hornby2006automated}, to data-parallel fitness evaluation of single individuals over independent test cases using hardware accelerators \citep{harding2007fast_springer, langdon2019continuous}, to application of primary-subordinate/controller-responder parallelism to delegate costly fitness evaluations of single individuals \citep{cantu2001master,miikkulainen2019evolving}.
In recent years, Sentient Technologies spearheaded evolutionary computation projects on an unprecedented computational scale, comprising over a million heterogeneous CPUs from time-available providers capable of a peak performance of 9 petaflops \citep{miikkulainen2019evolving,gilbert2015artificial,blondeau2009distributed}.

Although highlighted as key to the future of the field, fully decentralized, highly-distributed approaches such as island models \citep{bennett1999building,schulte2010genetic} and mesh-computing approaches prioritizing dynamic interactions \citep{ray1995proposal,ackley2018digital,moreno2021conduit} have been less thoroughly developed.
Observability constitutes a major barrier to effective applications of the fully-distributed paradigm: in the absence of a global population-level view, the course of evolution becomes much more challenging to study --- undercutting the objective of these systems as an experimental tool.

Difficulty scaling typical approaches to phylogenetic analyses of digital evolution systems poses a particularly problematic stumbling block.
Most existing analyses leverage a direct lineage tracking approach where a centralized data structure collates individual reproduction events to produce a complete, perfect phylogenetic record (TODO cite phylotrackpy)
%TODO we could probably add some citations/examples about why phylogenetic tracking is important
% AND how perfect phylogenetic tracking is super powerful at doing otherwise unimaginable analyses
% probably pilfer phylotrackpy JOSS paper for ideas
% TODO also tie in the algorithmic analysis of phylogenies here
However, long distance, potentially many-hop, transmission of reproduction event records to a centralized data store introduces potentially significant amounts of communication overhead and bottlenecking.
The necessity to propagate extinction notifications at runtime so that records of lineages without extant descendants can be pruned away to prevent runaway memory use imposes additional communication overhead.
Further, at large enough scales, node failures become inevitablies rather than inconveniences and, at even larger scales, the cost of attempting full recovery from node dropout to prevent data loss could become high enough to conceivably preclude forward simulation progress \citep{cappello2014toward}.
Within the perfect-tracking paradigm, individual missing relationships could potentially entirely disjoin knowledge of how large portions of phylogenetic history relate.
This sensitivity to data loss poses a second major challenge in scaling perfect tracking.

Looking to  natural systems, however, fruitful efforts across generations of systematic biologists evidence the viability of robust phylogenetic analyses from data generated through fully-distributed processes.
An alternate approach to studying phylogenetic dynamics in distributed systems, therefore, can be entertained: post-hoc inference from heritable data rather than centralized tracking.
Although such analyses can passably be accomplished solely from direct analysis of pre-existing, functional digital genome contents \citep{moreno2021case}, such algorithms do not generalize across diverse digital evolution systems and suffer from many of the complications that plague phylogenetic analyses of biological systems to boot (TODO cite).
This line of reasoning led to the recent development of hereditary stratigraphy methodology, which associates digital genomes with heritable annotations specially designed to provide universal system-invariant phylogenetic reconstruction with well-defined, tunable expectations for inference accuracy
\citep{moreno2022hereditary}.

Describe how hstrat works (briefly?)
mention \texttt{hstrat} software library \citep{moreno2022hstrat}



\begin{itemize}
  \item hereditary stratigraphy generalizes to broader question of replicating digital artifacts
  \item digital media and computer viruses
  \item existing studies generally employ centralized tracking
  \begin{itemize}
    \item image/text snippet sharing on facebook \citep{friggeri2014rumor}
    \item Experiments studying the propagation of computer viruses with centralized instrumentation \citep{cohen1987computer} (want more cites)
  \end{itemize}
  \item interesting instance of reconstruction that shares a lot in common with hereditary stratigraphy: chain email sharing \citep{libennowell2008tracing}
\end{itemize}

\begin{itemize}
  \item IoT/wireless sensor networks
  \item low power/capacity hardware: smart dust \citep{warneke2001smart}
  \item run out of space:
  \begin{itemize}
    \item long-duration solar-powered sensor --- battery is not limiting factor \citep{corke2007long}
    \item not just limited onboard memory
    \item high frequency data \citep{luharuka2003design}
  \end{itemize}
  \item common theme: irregular connectivity
  \begin{itemize}
    \item communicication outages/disruptions (need cite)
    \item query-based networks (need cite) (note ``security'' applications where desired content is only known long after the fact?)
    \item mobile sinks \citep{jain2022survey} (for security, power efficiency (fewer hops), reduce bottlenecking)
    \item at the very extreme are autonomous loggers
    \item logger: new data discarded once full \citep{saunders1989portable,mahzan2017design}
    \item logger: new data replaces oldest data (flight data recorder; need cite)
    \item logger: pplication-specific online compression algorithm that (\citep{hadiatna2016design} increases capacity twofold)
  \end{itemize}
  \item more data coming in from everywhere, also need a principled strategy to triage ``record management'' in centralized storage
  \item end on: need a principled way to weed time series data on the fly that meets coverage requirements at any point in time
\end{itemize}



then outline paper
\begin{itemize}
\item intro
\item preliminaries
\item perfect Tracking
\item policies
\item discussion
\end{itemize}
